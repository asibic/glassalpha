# ==============================================================================
# COMPAS Recidivism Dataset Audit Configuration
# ==============================================================================
#
# Dataset: COMPAS (Correctional Offender Management Profiling for Alternative Sanctions)
# Source: ProPublica's Machine Bias Investigation
# Size: 7,214 defendants
# Task: Predict two-year recidivism
# Protected Attributes: Race, sex, age
#
# This dataset is from ProPublica's landmark investigation into racial bias in
# criminal risk assessment algorithms. COMPAS scores are used in courts across
# the US to make bail, sentencing, and parole decisions.
#
# Download Instructions:
# Option 1 (ProPublica original):
#   wget https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv
#   mv compas-scores-two-years.csv ~/data/compas_recidivism.csv
#
# Option 2 (Kaggle):
#   https://www.kaggle.com/danofer/compass
#   Download and save as: ~/data/compas_recidivism.csv
#
# Key Findings from ProPublica (2016):
# - Black defendants were twice as likely to be misclassified as higher risk
# - White defendants were more likely to be misclassified as lower risk
# - Accuracy was similar across races (~60%) but errors were distributed unfairly
#
# Ethical Considerations:
# This is a controversial dataset involving criminal justice and racial bias.
# Use responsibly and consider the ethical implications of algorithmic justice.
#
# Documentation: https://glassalpha.com/getting-started/data-sources/#compas-recidivism
# Research Paper: https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing
# ==============================================================================

audit_profile: tabular_compliance

# Reproducibility settings
reproducibility:
  random_seed: 42
  deterministic: true
  capture_environment: true

# Data configuration
data:
  dataset: custom
  path: ~/data/compas_recidivism.csv # Update this path
  target_column: two_year_recid # Binary: 1 (recidivated) or 0 (did not)

  # Key features from COMPAS dataset
  feature_columns:
    - age
    - age_cat # Age category: Less than 25, 25-45, Greater than 45
    - sex
    - race
    - juv_fel_count # Juvenile felony count
    - juv_misd_count # Juvenile misdemeanor count
    - juv_other_count # Other juvenile offenses
    - priors_count # Prior offenses count
    - c_charge_degree # Charge degree (F: Felony, M: Misdemeanor)
    - c_charge_desc # Charge description
    # Note: We intentionally exclude 'decile_score' and 'score_text'
    # as these are COMPAS's own predictions

  # Protected attributes for fairness analysis
  protected_attributes:
    - race # Primary concern: African-American vs Caucasian disparities
    - sex # Gender disparities in criminal justice
    - age_cat # Age-based disparities

# Model configuration
model:
  type: logistic_regression # Recommended for interpretability in criminal justice
  # Note: For this high-stakes domain, interpretability > accuracy

  params:
    random_state: 42
    max_iter: 1000
    C: 1.0 # Regularization strength
    penalty: l2
    solver: lbfgs

# Explainer configuration
explainers:
  strategy: first_compatible
  priority:
    - coefficients # Best for LogisticRegression
    - permutation # Fallback

  config:
    permutation:
      n_repeats: 10
      random_state: 42

# Metrics configuration
metrics:
  performance:
    metrics:
      - accuracy
      - precision # Critical: false positives have severe consequences
      - recall # Critical: false negatives have severe consequences
      - f1
      - auc_roc
      - classification_report

  fairness:
    metrics:
      - demographic_parity # Equal prediction rates across races
      - equal_opportunity # Equal true positive rates (correctly identified recidivists)
      - equalized_odds # Equal TPR and FPR across groups
      - predictive_parity # Equal precision across groups

    config:
      # Stricter thresholds for criminal justice
      demographic_parity:
        threshold: 0.05 # Maximum 5% difference
      equal_opportunity:
        threshold: 0.05 # Equal opportunity to be correctly identified
      equalized_odds:
        threshold: 0.05 # Equal error rates

# Preprocessing configuration
# Note: Preprocessing options are coming in a future release
# GlassAlpha currently handles preprocessing automatically

# Report configuration
report:
  template: standard_audit
  output_format: pdf
  styling:
    color_scheme: professional
    compliance_statement: true

  include_sections:
    - executive_summary
    - data_overview
    - model_performance
    - global_explanations
    - fairness_analysis
    - audit_manifest
    - regulatory_compliance
# Manifest configuration
# Note: Manifest is automatically generated with each audit
# Custom manifest options are coming in a future release
# ==============================================================================
# Usage:
#   glassalpha audit --config compas_recidivism.yaml --output compas_audit.pdf --strict
#
# Expected Results:
# - Accuracy: ~65-70% (similar to original COMPAS)
# - Race bias: Likely detected (African-American vs Caucasian disparities)
# - False positive rate disparities across races
# - Equal opportunity violations (different TPRs across races)
#
# Interpreting Results:
# - High FPR for Black defendants = overclassified as high risk
# - High FNR for White defendants = underclassified as low risk
# - These disparities can lead to unjust bail/sentencing decisions
#
# Ethical Considerations:
# - This model replicates a controversial real-world system
# - Results show how ML can perpetuate systemic bias
# - Use for research and education, not production deployment
# - Consider alternatives to predictive risk assessment
#
# Troubleshooting:
# - If file not found: Update data.path to actual location
# - If target column missing: Check for 'is_recid' or 'recid' variations
# - If protected attributes missing: Verify column names match exactly
#
# Further Reading:
# - ProPublica's Machine Bias: https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing
# - Dressel & Farid (2018): "The accuracy, fairness, and limits of predicting recidivism"
# - Washington & Kuo (2020): "Whose Side Are Ethics Codes On?"
#
# Next Steps:
# - Compare results with ProPublica's findings
# - Try different fairness metrics and thresholds
# - Explore bias mitigation techniques
# - Document findings for policy advocacy
# ==============================================================================
