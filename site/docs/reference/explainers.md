# Explainer selection guide

Choose the right explainer to understand what drives your model's predictions.

!!! info "Quick Links" - **Haven't chosen a model yet?** ‚Üí Start with [Model Selection Guide](model-selection.md) - **Ready to configure?** ‚Üí See [Configuration Guide](../getting-started/configuration.md) for explainer YAML setup - **Getting started?** ‚Üí Try the [Quick Start Guide](../getting-started/quickstart.md) first

## Quick Decision Tree

```
                    Start Here
                        ‚Üì
           Is your model tree-based?
         (XGBoost, LightGBM, RandomForest)
                   ‚Üô        ‚Üò
                 YES         NO
                  ‚Üì           ‚Üì
         Is SHAP installed?  Is it LogisticRegression?
            ‚Üô        ‚Üò           ‚Üô        ‚Üò
          YES        NO        YES        NO
           ‚Üì          ‚Üì         ‚Üì          ‚Üì
     Use TreeSHAP  Use      Use         Use
     (exact,      Permutation Coefficients KernelSHAP
      fast)       (fast)     (instant)    (slower)
```

**TL;DR**:

- **Tree models + SHAP?** ‚Üí TreeSHAP (best choice)
- **Tree models, no SHAP?** ‚Üí Permutation
- **LogisticRegression?** ‚Üí Coefficients (fastest)
- **Other models?** ‚Üí KernelSHAP (universal fallback)

## Explainer Comparison

### Performance Benchmarks

Based on German Credit dataset (1,000 rows, 20 features):

| Explainer    | Time to Explain | Accuracy            | Memory | Dependencies |
| ------------ | --------------- | ------------------- | ------ | ------------ |
| TreeSHAP     | 2.3s            | Exact               | 150MB  | SHAP library |
| KernelSHAP   | 12.5s           | Approximate         | 80MB   | SHAP library |
| Permutation  | 1.8s            | Feature-level only  | 50MB   | None         |
| Coefficients | 0.1s            | Exact (linear only) | 10MB   | None         |

**Key takeaway**: TreeSHAP is 5x faster than KernelSHAP and provides exact values.

### Feature Comparison

| Feature                  | TreeSHAP | KernelSHAP | Permutation | Coefficients |
| ------------------------ | -------- | ---------- | ----------- | ------------ |
| **Model Compatibility**  | Trees    | Any        | Any         | Linear only  |
| **Accuracy**             | Exact    | Approx     | Global only | Exact        |
| **Speed**                | Fast     | Slow       | Fast        | Instant      |
| **Individual Samples**   | ‚úÖ Yes   | ‚úÖ Yes     | ‚ùå No       | ‚úÖ Yes       |
| **Feature Interactions** | ‚úÖ Yes   | ‚úÖ Yes     | ‚ùå No       | ‚ùå No        |
| **Installation**         | Optional | Optional   | Built-in    | Built-in     |
| **Interpretability**     | High     | High       | Medium      | Very High    |

## Detailed Explainer Profiles

### TreeSHAP

**Best for**: Tree-based models (XGBoost, LightGBM, RandomForest)

#### When to Choose TreeSHAP

**‚úÖ Choose if**:

- Your model is XGBoost, LightGBM, or RandomForest
- You have SHAP installed
- You want exact SHAP values (not approximations)
- You need fast explanation generation
- You want individual prediction explanations

**‚ùå Avoid if**:

- Your model is LogisticRegression or neural network
- You can't install the SHAP library
- You don't have tree-based models

#### Installation

```bash
# Install SHAP support
pip install 'glassalpha[explain]'

# Or just SHAP
pip install shap
```

#### Configuration Example

```yaml
explainers:
  strategy: first_compatible
  priority:
    - treeshap
  config:
    treeshap:
      max_samples: 1000 # Samples for background dataset
      check_additivity: true # Verify SHAP properties
```

#### How It Works

TreeSHAP computes exact Shapley values by leveraging the tree structure:

1. **Traverses tree paths**: Uses the model's internal tree structure
2. **Computes contributions**: Calculates exact feature contributions
3. **No approximation**: Unlike KernelSHAP, provides exact values
4. **Polynomial time**: Much faster than exponential KernelSHAP

**Mathematical guarantee**: TreeSHAP values satisfy all SHAP properties exactly.

#### Performance Characteristics

**Speed scaling**:

- **1K samples**: ~2 seconds
- **10K samples**: ~8 seconds
- **100K samples**: ~45 seconds

**Memory scaling**:

- Roughly 150MB per 1K samples
- Can be optimized with `max_samples` parameter

#### Strengths

- **Exact values**: No approximation error
- **Fast**: 5-10x faster than KernelSHAP
- **Individual explanations**: Explains specific predictions
- **Feature interactions**: Captures interaction effects
- **Well-established**: Proven in production use
- **Additive**: Values sum to prediction difference

#### Limitations

- **Tree models only**: Won't work with LogisticRegression or neural networks
- **Requires SHAP**: Optional dependency
- **Memory intensive**: Large models need more memory
- **Less interpretable**: Not as clear as coefficients

#### Real-World Use Cases

**Credit scoring**: Explain why a loan was denied with exact feature contributions
**Fraud detection**: Show which transaction features triggered fraud alert
**Risk assessment**: Break down risk score into individual factor contributions

---

### KernelSHAP

**Best for**: Non-tree models, universal fallback

#### When to Choose KernelSHAP

**‚úÖ Choose if**:

- Your model is not tree-based
- You need SHAP explanations for any model type
- You have SHAP installed
- Explanation time is not critical

**‚ùå Avoid if**:

- You have a tree-based model (use TreeSHAP instead)
- You need fast explanations (use Permutation)
- You can't install the SHAP library

#### Installation

```bash
# Install SHAP support
pip install 'glassalpha[explain]'
```

#### Configuration Example

```yaml
explainers:
  strategy: first_compatible
  priority:
    - kernelshap
  config:
    kernelshap:
      n_samples: 500 # More samples = better accuracy
      background_size: 100 # Background dataset size
```

#### How It Works

KernelSHAP approximates Shapley values through sampling:

1. **Creates coalitions**: Samples feature combinations
2. **Evaluates model**: Runs model on each coalition
3. **Fits regression**: Learns contribution weights
4. **Approximates**: Estimates Shapley values

**Trade-off**: More samples = better accuracy but slower

#### Performance Characteristics

**Speed scaling**:

- **1K samples, n_samples=100**: ~3 seconds
- **1K samples, n_samples=500**: ~12 seconds
- **10K samples, n_samples=500**: ~45 seconds

**Accuracy vs Speed**:

- **n_samples=100**: Fast but less accurate
- **n_samples=500**: Good balance (default)
- **n_samples=1000+**: Most accurate but slow

#### Strengths

- **Model-agnostic**: Works with any model type
- **Individual explanations**: Explains specific predictions
- **Feature interactions**: Captures interaction effects
- **SHAP guarantees**: Satisfies SHAP axioms (approximately)
- **Flexible**: Can tune accuracy vs speed

#### Limitations

- **Very slow**: 5-10x slower than TreeSHAP
- **Approximate**: Not exact like TreeSHAP
- **Requires SHAP**: Optional dependency
- **Memory intensive**: Stores many model evaluations
- **Hyperparameter sensitive**: n_samples affects results

#### Real-World Use Cases

**Neural networks**: Explain deep learning predictions
**Ensemble models**: Explain stacked or blended models
**Custom models**: Explain any black-box model

---

### Permutation

**Best for**: Quick feature importance without SHAP

#### When to Choose Permutation

**‚úÖ Choose if**:

- You want global feature importance (not individual explanations)
- You don't have SHAP installed
- You need fast explanations
- You want a simple, interpretable approach

**‚ùå Avoid if**:

- You need individual prediction explanations
- You want to capture feature interactions
- You need exact Shapley values

#### Configuration Example

```yaml
explainers:
  strategy: first_compatible
  priority:
    - permutation
  config:
    permutation:
      n_repeats: 10 # More repeats = more stable
      random_state: 42
```

#### How It Works

Permutation importance measures feature importance by:

1. **Baseline score**: Evaluate model on original data
2. **Shuffle feature**: Randomly permute one feature
3. **New score**: Evaluate model with shuffled feature
4. **Importance**: Difference in scores
5. **Repeat**: Do this for each feature

**Intuition**: Important features cause big score drops when shuffled

#### Performance Characteristics

**Speed scaling**:

- **1K samples**: ~1.8 seconds
- **10K samples**: ~8 seconds
- **100K samples**: ~35 seconds

**Stability**: More repeats = more stable but slower

#### Strengths

- **Fast**: Comparable to TreeSHAP
- **No dependencies**: Built-in to GlassAlpha
- **Model-agnostic**: Works with any model
- **Simple interpretation**: Easy to explain
- **Global view**: Shows overall feature importance

#### Limitations

- **No individual explanations**: Only global importance
- **No interactions**: Doesn't capture feature interactions
- **Less precise**: More variance than SHAP methods
- **Not additive**: Doesn't satisfy SHAP axioms

#### Real-World Use Cases

**Quick audits**: Fast feature importance for exploratory analysis
**No SHAP available**: When you can't install additional dependencies
**Global understanding**: When you only need overall feature rankings

---

### Coefficients

**Best for**: LogisticRegression and linear models

#### When to Choose Coefficients

**‚úÖ Choose if**:

- Your model is LogisticRegression or linear
- You want instant explanations
- You need maximum interpretability
- You want exact feature contributions

**‚ùå Avoid if**:

- Your model is not linear (XGBoost, neural networks, etc.)

#### Configuration Example

```yaml
model:
  type: logistic_regression

explainers:
  strategy: first_compatible
  priority:
    - coefficients # Automatic for LogisticRegression
```

#### How It Works

For LogisticRegression, coefficients directly show feature importance:

1. **Extract coefficients**: Get model weights
2. **Scale by feature**: Multiply by feature values
3. **Direct contribution**: Each coefficient is an exact contribution

**Mathematical clarity**: Œ≤‚ÇÅx‚ÇÅ + Œ≤‚ÇÇx‚ÇÇ + ... = prediction

#### Performance Characteristics

**Speed**: Instant (<0.1 seconds)
**Memory**: Minimal (~10MB)

#### Strengths

- **Instant**: No computation needed
- **Exact**: Not approximate
- **Highly interpretable**: Coefficients are clear
- **Individual explanations**: Shows contribution per sample
- **No dependencies**: Built-in
- **Additive**: Sums to prediction

#### Limitations

- **Linear models only**: Won't work with tree models or neural networks
- **No interactions**: Must manually create interaction terms
- **Feature scaling matters**: Coefficients depend on scale

#### Real-World Use Cases

**Regulatory compliance**: Maximum transparency for regulators
**Legal explanations**: Clear, defensible explanations
**Baseline models**: Quick interpretable baseline

---

## Choose Your Own Adventure

### I have XGBoost and SHAP installed...

**Use**: TreeSHAP

**Why**:

- Exact SHAP values
- Fast computation
- Individual explanations
- Industry standard

**Configuration**:

```yaml
explainers:
  strategy: first_compatible
  priority:
    - treeshap
  config:
    treeshap:
      max_samples: 1000
      check_additivity: true
```

**Expected time**: 2-5 seconds for 1K samples

---

### I have XGBoost but no SHAP...

**Use**: Permutation

**Why**:

- No dependencies required
- Still reasonably fast
- Model-agnostic
- Good for global importance

**Configuration**:

```yaml
explainers:
  strategy: first_compatible
  priority:
    - permutation
  config:
    permutation:
      n_repeats: 10
      random_state: 42
```

**Expected time**: 2-8 seconds for 1K samples

---

### I'm using LogisticRegression...

**Use**: Coefficients

**Why**:

- Instant results
- Maximum interpretability
- Exact contributions
- No dependencies

**Configuration**:

```yaml
model:
  type: logistic_regression

explainers:
  strategy: first_compatible
  priority:
    - coefficients
```

**Expected time**: <0.1 seconds

---

### I have a custom/unusual model...

**Use**: KernelSHAP or Permutation

**Why**:

- Works with any model
- KernelSHAP for individual explanations
- Permutation for global importance

**Configuration**:

```yaml
explainers:
  strategy: first_compatible
  priority:
    - kernelshap # If SHAP installed
    - permutation # Fallback
  config:
    kernelshap:
      n_samples: 500
```

**Expected time**: 10-30 seconds for 1K samples

---

## Explainer Selection by Use Case

### Credit Scoring (XGBoost)

**Recommended**: TreeSHAP

**Why**: Regulators want exact, defensible explanations

**Configuration**:

```yaml
explainers:
  strategy: first_compatible
  priority:
    - treeshap
  config:
    treeshap:
      max_samples: 1000
      check_additivity: true # Verify exactness
```

---

### Fraud Detection (Large Scale)

**Recommended**: Permutation

**Why**: Speed is critical, global importance sufficient

**Configuration**:

```yaml
explainers:
  strategy: first_compatible
  priority:
    - permutation
  config:
    permutation:
      n_repeats: 5 # Reduce for speed
```

---

### Healthcare (High Stakes)

**Recommended**: TreeSHAP or Coefficients

**Why**: Maximum transparency and exactness required

**Configuration**:

```yaml
# For tree models:
explainers:
  priority:
    - treeshap
  config:
    treeshap:
      check_additivity: true

# For linear models:
model:
  type: logistic_regression
explainers:
  priority:
    - coefficients
```

---

### Hiring/HR

**Recommended**: Coefficients (LogisticRegression)

**Why**: Maximum interpretability for fairness audits

**Configuration**:

```yaml
model:
  type: logistic_regression

explainers:
  strategy: first_compatible
  priority:
    - coefficients
```

---

## Common Questions

### What's the difference between TreeSHAP and KernelSHAP?

**TreeSHAP**:

- **Exact** Shapley values
- **Fast** (uses tree structure)
- **Tree models only**

**KernelSHAP**:

- **Approximate** Shapley values
- **Slower** (samples coalitions)
- **Any model type**

**Rule**: Use TreeSHAP for tree models, KernelSHAP for everything else

### Do I need SHAP for good explanations?

**No!** GlassAlpha provides great explanations without SHAP:

- **LogisticRegression**: Use coefficients (even better than SHAP)
- **XGBoost/LightGBM**: Use permutation importance
- **Any model**: Permutation works universally

SHAP is better for individual predictions, but not required.

### How much does SHAP really improve explanations?

**For tree models**: Significant improvement

- TreeSHAP: Individual explanations, exact values
- Permutation: Only global importance, less precise

**For linear models**: Minimal improvement

- Coefficients: Already exact and interpretable
- SHAP: Adds complexity without benefit

**Bottom line**: SHAP is worth it for tree models, less so for linear models

### Can I use multiple explainers?

Yes! GlassAlpha will use the first compatible explainer from your priority list:

```yaml
explainers:
  priority:
    - treeshap # Try first
    - kernelshap # Fallback if treeshap not available
    - permutation # Universal fallback
```

### What if explanation is too slow?

**For TreeSHAP**:

```yaml
config:
  treeshap:
    max_samples: 100 # Reduce from 1000
```

**For KernelSHAP**:

```yaml
config:
  kernelshap:
    n_samples: 100 # Reduce from 500
```

**Or switch to Permutation**:

```yaml
priority:
  - permutation # Much faster
```

## Performance Tuning

### Optimizing TreeSHAP

**For speed**:

```yaml
treeshap:
  max_samples: 100 # Fewer samples
  check_additivity: false # Skip verification
```

**For accuracy**:

```yaml
treeshap:
  max_samples: 2000 # More samples
  check_additivity: true # Verify exactness
```

### Optimizing KernelSHAP

**Fast but less accurate**:

```yaml
kernelshap:
  n_samples: 100
  background_size: 50
```

**Slow but more accurate**:

```yaml
kernelshap:
  n_samples: 1000
  background_size: 500
```

### Optimizing Permutation

**Faster**:

```yaml
permutation:
  n_repeats: 5 # Reduce from 10
```

**More stable**:

```yaml
permutation:
  n_repeats: 20 # Increase from 10
```

## Understanding Explainer Output

### TreeSHAP / KernelSHAP Output

**Global feature importance**:

```
Feature                 | Mean |SHAP|
------------------------|------------
checking_account_status | 0.234
credit_history          | 0.187
duration_months         | -0.156
credit_amount           | -0.142
```

**Individual prediction**:

```
Base value: 0.70 (70% approval rate)

Contributions:
+ checking_account (positive): +0.15
+ credit_history (good):       +0.12
+ age (35):                    +0.04
- duration_months (36):        -0.08
- credit_amount (5000):        -0.05
= Final prediction: 0.88 (88% approval)
```

### Permutation Output

**Feature importance ranking**:

```
Feature                 | Importance
------------------------|------------
checking_account_status | 0.089
credit_history          | 0.076
duration_months         | 0.054
credit_amount           | 0.048
```

**Interpretation**: Shuffling `checking_account_status` drops accuracy by 8.9%

### Coefficients Output

**Feature contributions**:

```
Feature                 | Coefficient | Contribution
------------------------|-------------|-------------
checking_account_status | 1.2         | +0.84
credit_history          | 0.8         | +0.56
duration_months         | -0.02       | -0.72
credit_amount           | -0.0001     | -0.50
Intercept               | -0.5        | -0.50
                                     = 0.68 (68%)
```

## Technical Deep Dive

### Why TreeSHAP is Faster

Traditional SHAP requires 2^n model evaluations for n features.

TreeSHAP exploits tree structure:

- Polynomial time instead of exponential
- Leverages decision tree paths
- No sampling required
- Mathematically equivalent results

**Result**: 100x+ speedup with exact values

### SHAP Axioms Explained

SHAP values satisfy important properties:

1. **Additivity**: Values sum to prediction difference
2. **Symmetry**: Similar features get similar values
3. **Dummy**: Irrelevant features get zero value
4. **Efficiency**: Values sum exactly to output

These properties make SHAP values trustworthy for explanations.

### When SHAP Can Be Misleading

**Correlated features**:

- SHAP distributes credit among correlated features
- Can underestimate individual feature importance
- Solution: Consider feature groups

**High-cardinality categoricals**:

- Many categories can lead to unstable SHAP values
- Solution: Group rare categories

**Extreme values**:

- Outliers can dominate SHAP values
- Solution: Examine distribution of SHAP values

## Next Steps

Now that you've chosen your explainer:

1. **‚úÖ Configure**: Use the examples above to set up your explainer
2. **üìä Run audit**: Generate explanations in your audit report
3. **üîç Interpret**: Understand what drives your model's decisions
4. **‚öôÔ∏è Optimize**: Tune parameters for your speed/accuracy needs

## Additional Resources

- [Model Selection](model-selection.md) - Choose the right model first
- [Using Custom Data](../getting-started/custom-data.md) - Prepare your data
- [Configuration Guide](../getting-started/configuration.md) - Full configuration reference
- [FAQ](faq.md) - Common explainer questions

---

**Questions?** Open an issue on [GitHub](https://github.com/GlassAlpha/glassalpha/issues) or check the [FAQ](faq.md).
